<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Softwares, Economics on Muhsin Ciftci</title>
    <link>/tags/softwares-economics/</link>
    <description>Recent content in Softwares, Economics on Muhsin Ciftci</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="/tags/softwares-economics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Computer Softwares for Economics</title>
      <link>/post/2018-09-softwares/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-09-softwares/</guid>
      <description>&lt;p&gt;Those who study economics and finance or any relavant discipline begin to be exposed to different softwares to benefit from the real life data at hand. From my point of view and experience, an important question emerges out of this process: Which one should I use or is there any single software that can possibly meet all my needs to perform my tasks. The answer to this question very much depends on the specific subject area you work on. To put it in a different way, there is no an ideal single software that performs very well for each area. This leads us to the subject area we work again. Depending on the tasks we work on we may prefer different ones and dismiss others. For instance, those who concentrate on macroeconomics and economic modeling use &lt;code&gt;Matlab&lt;/code&gt; or &lt;code&gt;Octave&lt;/code&gt; because they allow macro guys to run &lt;code&gt;Dynare&lt;/code&gt; that is specifically written for Dynamic Stochastic General Equilibrium (DSGE) models. In that sense, for those who plan to get a Master or Ph.D on macro area are well advised to learn &lt;code&gt;Matlab&lt;/code&gt;. However, this is only a piece of the whole picture. If you deal with econometrics or statistics you can use &lt;code&gt;Stata&lt;/code&gt;, &lt;code&gt;Eviews&lt;/code&gt; or &lt;code&gt;R&lt;/code&gt; and each of them is well suited for very specific sub area. To make myself more clear, if you generally use micro/panel data, &lt;code&gt;Stata&lt;/code&gt; is really the best option. The loop and conditional statements are really handy. However, if you focus on time series econometrics, it is better to use &lt;code&gt;Eviews&lt;/code&gt;. It has click-on menus and really handy for quick and short analysis of time series. From this perspective, &lt;code&gt;Eviews&lt;/code&gt; outperforms &lt;code&gt;Stata&lt;/code&gt; but it is really bad for micro/panel data analysis. I should point out that in each of them you can do what want but it comes at higher cost! Therefore, the actual point is to minimize the cost that we put on using those softwares. On the other hand, we can do all this econometric staff on &lt;code&gt;R&lt;/code&gt; as well but it does not have click-on menus and it might be a little onerous to get used to. However, &lt;code&gt;R&lt;/code&gt; is great for data analysis and data visulaziation. As we all observe, the data science begins to get importance each day mainly due to the large and complex data becoming available. Therefore, &lt;code&gt;R&lt;/code&gt; is a big and potential software to invest in. What is more, it is free and you can find almost anything in it with myriads of different packages.&lt;/p&gt;

&lt;p&gt;On the other hand, the preferences on using softwares are also subject to change! As technology improves, the capabilities of new softwares also begin to outperform that of old ones. Also these new softwares are free and their codes are available on different platforms. You can develop a package or contribute to. This feature of new softwares makes them to expand very quickly and to have very active communities. One of the most populer and excellent one is &lt;code&gt;Python&lt;/code&gt;. It is really useful for data analysis and it has different scientific libraries. Because of the rise of &lt;code&gt;Python&lt;/code&gt;, &lt;code&gt;Matlab&lt;/code&gt; begins to lose its popularity even among macro guys.&lt;/p&gt;

&lt;p&gt;However, in all of these softwares we have an important problem: &lt;em&gt;Speed&lt;/em&gt;. Depending on your subject, speed may become an important factor for you analysis. For example, even though &lt;code&gt;Python&lt;/code&gt; is really usefull for data anaylsis and it has different scientific libraries, perhaps it is not as much fast as we want! At this point we meet the Big Boss: &lt;code&gt;Julia&lt;/code&gt;. &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia&lt;/a&gt; language is developed by &lt;code&gt;MIT&lt;/code&gt;. Its syntax is very similar to that of &lt;code&gt;Matlab&lt;/code&gt; and &lt;code&gt;Python&lt;/code&gt; and it does not bring a big time cost if you want to learn. The beauty of &lt;code&gt;Julia&lt;/code&gt; is that it is very fast, because of its property called &lt;code&gt;Multiple Dispatch&lt;/code&gt;. It is almost as fast as &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;Fortran&lt;/code&gt; with very clean syntax. That makes &lt;code&gt;Julia&lt;/code&gt; really fun to work with. For example, Federal Reserve Bank of NewYork has switched to &lt;code&gt;Julia&lt;/code&gt; for their DSGE models because of &lt;code&gt;Julia&lt;/code&gt;&amp;rsquo;s speed (it is much faster than Matlab). These properties of new softwares are really killing &lt;code&gt;Matlab&lt;/code&gt;. Furthermore, &lt;code&gt;Julia&lt;/code&gt; also have different packages for data analysis and the &lt;code&gt;Julia&lt;/code&gt; community is really expanding too much fast.&lt;/p&gt;

&lt;p&gt;All in all, the answer to the question that which software to use really depends on what you do. For those who wonder, &lt;code&gt;Julia&lt;/code&gt; is my favorite language and I really recommend to make an investment in &lt;code&gt;Julia&lt;/code&gt;. It is the future of scientific programming!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Basic Gibbs Sampler</title>
      <link>/post/2017-09-gibbs/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017-09-gibbs/</guid>
      <description>&lt;p&gt;&lt;code&gt;Gibbs Sampler&lt;/code&gt;, which is a specific case of &lt;code&gt;MH algorithm&lt;/code&gt;, allows us to come up with values of ($\beta$, $\Sigma$) from joint distributions. Assuming that we have starting values for $\beta$ and $\Sigma$, and call them  $\beta^0$ and $\Sigma^0$. With those we will sample from the density of one element of parameter vector, conditional on the value of the other element sampled in the previous iteration. Thus the sampler will follow a recursive procedure. At the end we need to remove the effects of initial draws, which we call &lt;code&gt;burn-in&lt;/code&gt; period. Lets take a bivariate example for Normal Distribution for which say we have $X$ is distributed as $N(0, \Sigma)$ and $\rho$ stands for the cross correlation between $x_1$ and $x_2$. The following code of &lt;a href=&#34;https://julialang.org/&#34; target=&#34;_blank&#34;&gt;Julia Language&lt;/a&gt; will mimic this recursive procedure.&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/muhsinciftci/b59b94a1a73ce892ba23190c5dc57e19.js&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
  </channel>
</rss>
